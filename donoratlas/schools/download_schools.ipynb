{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 1.5 hour runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON, SPARQLExceptions\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_scan = ['wd:Q38723', 'wd:Q189004', 'wd:Q3918', 'wd:Q62078547', 'wd:Q269770', 'wd:Q12241709', 'wd:Q428602', 'wd:Q9826', 'wd:Q64063386', 'wd:Q149566', 'wd:Q875538', 'wd:Q159334', 'wd:Q3914', 'wd:Q2385804', 'wd:Q5341295', 'wd:Q902104', 'wd:Q1377182', 'wd:Q6540832', 'wd:Q494230', 'wd:Q1321960', 'wd:Q1143635', 'wd:Q20820271', 'wd:Q1663017', 'wd:Q423208', 'wd:Q11391922', 'wd:Q352102']\n",
    "\n",
    "avg_len = 3\n",
    "remainder = 0\n",
    "sub_arrays = []\n",
    "start = 0\n",
    "\n",
    "for i in range(9):\n",
    "    end = start + avg_len + (1 if i < remainder else 0)\n",
    "    sub_arrays.append(categories_to_scan[start:end])\n",
    "    start = end\n",
    "\n",
    "categories = sub_arrays\n",
    "print('running on categories:', categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikidata_entities(file):\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    \n",
    "    for categories_subset in tqdm(categories, desc=\"Processing Categories\"):\n",
    "        query = f\"\"\"\n",
    "            SELECT ?institution ?instance WHERE {{\n",
    "            VALUES ?instance {{{' '.join(categories_subset)}}}\n",
    "            {{\n",
    "                ?institution wdt:P31 ?instance .\n",
    "            }}\n",
    "            UNION\n",
    "            # Second layer: Subclasses of instances (subclass of a subclass)\n",
    "            {{\n",
    "                ?subclass wdt:P279* ?instance .\n",
    "                ?institution wdt:P31* ?subclass .\n",
    "            }}\n",
    "            \n",
    "            OPTIONAL {{ ?institution wdt:P17 ?country . }}\n",
    "            FILTER (!BOUND(?country) || ?country = wd:Q30)\n",
    "            }}\n",
    "\n",
    "            GROUP BY ?institution ?instance\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        try:\n",
    "            # Execute the query\n",
    "            results = sparql.query().convert()['results']['bindings']\n",
    "            result_lst.extend(results)\n",
    "            for result in results:\n",
    "                file.write(str(result))\n",
    "\n",
    "            print(f'adding {len(results)} entries to result_lst')\n",
    "            print(len(result_lst))\n",
    "            # Process the results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    return result_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikidata_entities_subset(file, categories_subset):\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    \n",
    "    for category in tqdm(categories_subset, desc=\"Processing Categories\"):\n",
    "        query = f\"\"\"\n",
    "            SELECT ?institution ?instance WHERE {{\n",
    "            VALUES ?instance {{{category}}}\n",
    "\n",
    "            ?institution wdt:P31 ?instance .\n",
    "            \n",
    "            OPTIONAL {{ ?institution wdt:P17 ?country . }}\n",
    "            FILTER (!BOUND(?country) || ?country = wd:Q30)\n",
    "            }}\n",
    "\n",
    "            GROUP BY ?institution ?instance\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        try:\n",
    "            # Execute the query\n",
    "            results = sparql.query().convert()['results']['bindings']\n",
    "            result_lst.extend(results)\n",
    "            for result in results:\n",
    "                file.write(str(result))\n",
    "\n",
    "            print(f'adding {len(results)} entries to result_lst')\n",
    "            print(len(result_lst))\n",
    "            # Process the results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT ?institution ?instance WHERE {{\n",
    "            VALUES ?instance {{{categories[4][1]}}}\n",
    "            \n",
    "            ?subclass wdt:P279 ?instance .\n",
    "            ?institution wdt:P31 ?subclass .\n",
    "            \n",
    "            OPTIONAL {{ ?institution wdt:P17 ?country . }}\n",
    "            FILTER (!BOUND(?country) || ?country = wd:Q30)\n",
    "            }}\n",
    "\n",
    "            GROUP BY ?institution ?instance\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        try:\n",
    "            # Execute the query\n",
    "            results = sparql.query().convert()['results']['bindings']\n",
    "            result_lst.extend(results)\n",
    "            for result in results:\n",
    "                file.write(str(result))\n",
    "\n",
    "            print(f'adding {len(results)} entries to result_lst')\n",
    "            print(len(result_lst))\n",
    "            # Process the results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    return result_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'wikidata_entites_{time.time()}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'w') as file:\n",
    "    df_entities = fetch_wikidata_entities(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on any categories that timed out\n",
    "category = [categories[4][1]]\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    df_entities = fetch_wikidata_entities_subset(file, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities = pd.DataFrame(df_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate ids\n",
    "df_unique = df_entities.drop_duplicates(subset=\"institution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities = df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities['institution_id'] = df_entities['institution'].apply(lambda x: x['value'].split('/')[-1])\n",
    "\n",
    "# Write the extracted IDs to a text file\n",
    "output_file = \"institution_ids.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.writelines(f\"{inst_id}\\n\" for inst_id in df_entities['institution_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get each entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entity(results: List[dict], entity_id):\n",
    "    \"\"\"\n",
    "    Aggregates the input data into a dictionary where the key is valueLabel['value'] \n",
    "    and the value is a dictionary mapping propertyLabel['value'] to valueLabel['value'].\n",
    "\n",
    "    Args:\n",
    "        data (list of dict): List of dictionaries containing 'valueLabel' and 'propertyLabel'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Aggregated dictionary.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "\n",
    "    if results:\n",
    "        for item in results:\n",
    "            value_label = item[\"valueLabel\"][\"value\"]\n",
    "            property_label = item[\"propertyLabel\"][\"value\"]\n",
    "\n",
    "            # Initialize nested dictionary for the value_label if not already present\n",
    "            if property_label not in aggregated:\n",
    "                aggregated[property_label] = [value_label]\n",
    "            else:\n",
    "                aggregated[property_label].append(value_label)\n",
    "        aggregated['wd_id'] = entity_id\n",
    "        aggregated['name'] = results[0]['itemLabel']['value']\n",
    "        return aggregated\n",
    "    else:\n",
    "        print(\"no results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(match):\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT ?itemLabel ?propertyLabel ?valueLabel ?altLabel WHERE {{\n",
    "            BIND(wd:{match} AS ?item)  # Bind the input entity to ?item\n",
    "            ?item ?prop ?value .\n",
    "            ?property wikibase:directClaim ?prop .\n",
    "\n",
    "            OPTIONAL {{\n",
    "                ?value rdfs:label ?valueLabel .\n",
    "                FILTER (lang(?valueLabel) = \"en\")\n",
    "            }}\n",
    "\n",
    "            OPTIONAL {{ ?item skos:altLabel ?altLabel . FILTER (LANG(?altLabel) = \"en\") }}\n",
    "\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    results = sparql.query().convert()\n",
    "    results = results['results']['bindings']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fetch_entity_with_retry(entity, max_retries=5, backoff_factor=1.5):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Replace this with the actual API call\n",
    "            result = get_entity(entity)  # Your function that fetches the entity\n",
    "            return result\n",
    "        except SPARQLExceptions.QueryBadFormed as e:\n",
    "            print(\"Bad query format:\", e)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # Check for Retry-After header in response\n",
    "            if hasattr(e, \"response\") and e.response:\n",
    "                retry_after = e.response.headers.get(\"Retry-After\")\n",
    "                if retry_after:\n",
    "                    wait_time = int(retry_after)\n",
    "                    print(f\"Rate limit hit. Retrying after {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(\"Retry-After header not found. Retrying after 5 seconds...\")\n",
    "                    time.sleep(5)\n",
    "            else:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                break\n",
    "        # except Exception as e:\n",
    "        #     # If a 429 error occurs, handle it\n",
    "        #         retries += 1\n",
    "        #         wait_time = backoff_factor ** retries + random.uniform(0, 4)\n",
    "        #         print(f\"Rate limit hit. Retrying in {wait_time:.2f} seconds...\")\n",
    "        #         time.sleep(wait_time)\n",
    "    print(f\"Max retries reached. Skipping {entity}\")\n",
    "    return None  # Return None if retries are exhausted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 1h20m\n",
    "\n",
    "all_res = []\n",
    "output_txt = f\"raw_wiki_entities_{time.time()}.txt\"\n",
    "print(f'writing entities to {output_txt}')\n",
    "\n",
    "with open('institution_ids_429_11_25.txt', 'r') as file:\n",
    "    # Read all lines and store them in a list\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Strip the newline characters from each line\n",
    "results = [line.strip() for line in lines]\n",
    "if results:\n",
    "    for entity_id in tqdm(results, desc=\"Processing Entities\", unit=\"entity\", miniters=100, mininterval=0.5):\n",
    "        entity_data = fetch_entity_with_retry(entity_id)  # Retry logic added here\n",
    "        if entity_data:\n",
    "            entity_data = process_entity(entity_data, entity_id)  # Process the entity after fetching\n",
    "            with open(output_txt, mode=\"a\", encoding=\"utf-8\") as txtfile:\n",
    "                # Format the entity data as a string for writing\n",
    "                txtfile.write(f\"{str(entity_data)}\\n\")\n",
    "            \n",
    "            all_res.append(entity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "file_path = 'wiki_entities_11_25.txt'\n",
    "data = []\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        try:\n",
    "            # Safely evaluate the Python-like dictionary format\n",
    "            record = ast.literal_eval(line.strip())\n",
    "            data.append(record)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error on line {i}: {line.strip()}\")\n",
    "            print(f\"JSONDecodeError: {e}\")\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinate location</th>\n",
       "      <th>Commons category</th>\n",
       "      <th>NLA Trove people ID</th>\n",
       "      <th>endowment</th>\n",
       "      <th>VIAF ID</th>\n",
       "      <th>Microsoft Academic ID</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>HAL structure ID</th>\n",
       "      <th>Integrated Postsecondary Education Data System ID</th>\n",
       "      <th>LittleSis organization ID</th>\n",
       "      <th>...</th>\n",
       "      <th>intangible cultural heritage status</th>\n",
       "      <th>payload mass</th>\n",
       "      <th>theorised by</th>\n",
       "      <th>PubMed publication ID</th>\n",
       "      <th>author name string</th>\n",
       "      <th>Gateway to Research Project ID</th>\n",
       "      <th>principal investigator</th>\n",
       "      <th>funding scheme</th>\n",
       "      <th>Dictionary of Archives Terminology ID</th>\n",
       "      <th>officeholder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coordinate location Commons category NLA Trove people ID endowment  \\\n",
       "70212                 NaN              NaN                 NaN       NaN   \n",
       "\n",
       "      VIAF ID Microsoft Academic ID subreddit HAL structure ID  \\\n",
       "70212     NaN                   NaN       NaN              NaN   \n",
       "\n",
       "      Integrated Postsecondary Education Data System ID  \\\n",
       "70212                                               NaN   \n",
       "\n",
       "      LittleSis organization ID  ... intangible cultural heritage status  \\\n",
       "70212                       NaN  ...                                 NaN   \n",
       "\n",
       "      payload mass theorised by PubMed publication ID author name string  \\\n",
       "70212          NaN          NaN                   NaN                NaN   \n",
       "\n",
       "      Gateway to Research Project ID principal investigator funding scheme  \\\n",
       "70212                            NaN                    NaN            NaN   \n",
       "\n",
       "      Dictionary of Archives Terminology ID officeholder  \n",
       "70212                                   NaN          NaN  \n",
       "\n",
       "[1 rows x 1510 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['coordinate location', 'Commons category', 'NLA Trove people ID',\n",
       "       'endowment', 'VIAF ID', 'Microsoft Academic ID', 'subreddit',\n",
       "       'HAL structure ID', 'Integrated Postsecondary Education Data System ID',\n",
       "       'LittleSis organization ID',\n",
       "       ...\n",
       "       'intangible cultural heritage status', 'payload mass', 'theorised by',\n",
       "       'PubMed publication ID', 'author name string',\n",
       "       'Gateway to Research Project ID', 'principal investigator',\n",
       "       'funding scheme', 'Dictionary of Archives Terminology ID',\n",
       "       'officeholder'],\n",
       "      dtype='object', length=1510)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = df.shape[1]\n",
    "print(num_columns)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ids that were lost to 429 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "\n",
    "institutions_file = 'institution_ids.txt'\n",
    "output_file = \"missing_ids.txt\"\n",
    "\n",
    "# Read institutions.txt\n",
    "with open(institutions_file, \"r\") as f:\n",
    "    institution_ids = {line.strip() for line in f.readlines()}\n",
    "\n",
    "# Read processed_entities.txt and extract 'wd_id' values\n",
    "processed_ids = set()\n",
    "with open(processed_entities_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entity = ast.literal_eval(line.strip())\n",
    "            \n",
    "            # Check if 'wd_id' exists and process it\n",
    "            if isinstance(entity, dict) and 'wd_id' in entity:\n",
    "                processed_ids.add(entity['wd_id'])\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding line: {line.strip()}\")  # Optional: handle or log malformed lines\n",
    "\n",
    "# Compute the difference\n",
    "missing_ids = institution_ids - processed_ids\n",
    "\n",
    "# Write missing IDs to output file\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.writelines(f\"{wd_id}\\n\" for wd_id in missing_ids)\n",
    "\n",
    "print(f\"Missing IDs written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_txt = f\"processed_entities_{time.time()}.txt\"\n",
    "print(f'writing entities to {output_txt}')\n",
    "\n",
    "# results = fetch_wikidata_entities()\n",
    "results = missing_ids\n",
    "if results:\n",
    "    for entity_id in tqdm(results, desc=\"Processing Entities\", unit=\"entity\"):\n",
    "        entity_data = fetch_entity_with_retry(entity_id)  # Retry logic added here\n",
    "        if entity_data:\n",
    "            entity_data = process_entity(entity_data, entity_id)  # Process the entity after fetching\n",
    "            with open(output_txt, mode=\"a\", encoding=\"utf-8\") as txtfile:\n",
    "                # Format the entity data as a string for writing\n",
    "                txtfile.write(f\"{str(entity_data)}\\n\")\n",
    "            \n",
    "            all_res.append(entity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = df.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Michigan Technological University' 'University of Massachusetts Amherst'\n",
      " 'University of Massachusetts Boston' ... 'Q116134275' 'Q116134398'\n",
      " 'Q116134482']\n"
     ]
    }
   ],
   "source": [
    "print(df['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 16863 items without a name\n"
     ]
    }
   ],
   "source": [
    "# Count rows before filtering\n",
    "initial_count = len(df)\n",
    "\n",
    "# Drop schools without names\n",
    "df.drop(df[df['name'] == df['wd_id']].index, inplace=True)\n",
    "\n",
    "# Count rows after filtering\n",
    "final_count = len(df)\n",
    "\n",
    "# Calculate and print the number of dropped rows\n",
    "dropped_count = initial_count - final_count\n",
    "print(f\"Dropping {dropped_count} items without a name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 926 items without an instance of. 58237 entities remaining.\n"
     ]
    }
   ],
   "source": [
    "# Count rows before filtering\n",
    "initial_count = len(df)\n",
    "\n",
    "# Drop items without instance of\n",
    "df = df.dropna(subset=['instance of'])\n",
    "\n",
    "# Count rows after filtering\n",
    "final_count = len(df)\n",
    "\n",
    "# Calculate and print the number of dropped rows\n",
    "dropped_count = initial_count - final_count\n",
    "print(f\"Dropping {dropped_count} items without an instance of. {final_count} entities remaining.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 460 columns without any content\n"
     ]
    }
   ],
   "source": [
    "# drop all columns where one or zero rows have value\n",
    "\n",
    "initial_count = df.shape[1]\n",
    "\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df = df.loc[:, df.notna().sum() > 1]\n",
    "df = df[['name'] + ['wd_id'] + [col for col in df.columns if col != 'name' and col != 'wd_id']]\n",
    "\n",
    "final_count = df.shape[1]\n",
    "dropped_count = initial_count - final_count\n",
    "print(f\"Dropping {dropped_count} columns without any content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>wd_id</th>\n",
       "      <th>coordinate location</th>\n",
       "      <th>Commons category</th>\n",
       "      <th>NLA Trove people ID</th>\n",
       "      <th>endowment</th>\n",
       "      <th>VIAF ID</th>\n",
       "      <th>Microsoft Academic ID</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>HAL structure ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ICANNWiki page ID</th>\n",
       "      <th>discontinued date</th>\n",
       "      <th>editor</th>\n",
       "      <th>programmed in</th>\n",
       "      <th>IFTTT service ID</th>\n",
       "      <th>SlideShare username</th>\n",
       "      <th>WikiProjectMed ID</th>\n",
       "      <th>APA Dictionary of Psychology entry</th>\n",
       "      <th>NCI Thesaurus ID</th>\n",
       "      <th>J. Paul Getty Museum agent ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14314</th>\n",
       "      <td>Edward M. Kennedy Academy for Health Careers</td>\n",
       "      <td>Q5344270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30007</th>\n",
       "      <td>Brighter Star Secondary School</td>\n",
       "      <td>Q4967521</td>\n",
       "      <td>[Point(87.686 26.6602)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8437</th>\n",
       "      <td>University of California San Francisco Departm...</td>\n",
       "      <td>Q101028858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49721</th>\n",
       "      <td>Woodridge School District 68</td>\n",
       "      <td>Q85816135</td>\n",
       "      <td>[Point(-88.039738 41.7411379), Point(-88.03973...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64447</th>\n",
       "      <td>Institute for Mind and Body, University of Chi...</td>\n",
       "      <td>Q112085273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name       wd_id  \\\n",
       "14314       Edward M. Kennedy Academy for Health Careers    Q5344270   \n",
       "30007                     Brighter Star Secondary School    Q4967521   \n",
       "8437   University of California San Francisco Departm...  Q101028858   \n",
       "49721                       Woodridge School District 68   Q85816135   \n",
       "64447  Institute for Mind and Body, University of Chi...  Q112085273   \n",
       "\n",
       "                                     coordinate location Commons category  \\\n",
       "14314                                                NaN              NaN   \n",
       "30007                            [Point(87.686 26.6602)]              NaN   \n",
       "8437                                                 NaN              NaN   \n",
       "49721  [Point(-88.039738 41.7411379), Point(-88.03973...              NaN   \n",
       "64447                                                NaN              NaN   \n",
       "\n",
       "      NLA Trove people ID endowment VIAF ID Microsoft Academic ID subreddit  \\\n",
       "14314                 NaN       NaN     NaN                   NaN       NaN   \n",
       "30007                 NaN       NaN     NaN                   NaN       NaN   \n",
       "8437                  NaN       NaN     NaN                   NaN       NaN   \n",
       "49721                 NaN       NaN     NaN                   NaN       NaN   \n",
       "64447                 NaN       NaN     NaN                   NaN       NaN   \n",
       "\n",
       "      HAL structure ID  ... ICANNWiki page ID discontinued date editor  \\\n",
       "14314              NaN  ...               NaN               NaN    NaN   \n",
       "30007              NaN  ...               NaN               NaN    NaN   \n",
       "8437               NaN  ...               NaN               NaN    NaN   \n",
       "49721              NaN  ...               NaN               NaN    NaN   \n",
       "64447              NaN  ...               NaN               NaN    NaN   \n",
       "\n",
       "      programmed in IFTTT service ID SlideShare username WikiProjectMed ID  \\\n",
       "14314           NaN              NaN                 NaN               NaN   \n",
       "30007           NaN              NaN                 NaN               NaN   \n",
       "8437            NaN              NaN                 NaN               NaN   \n",
       "49721           NaN              NaN                 NaN               NaN   \n",
       "64447           NaN              NaN                 NaN               NaN   \n",
       "\n",
       "      APA Dictionary of Psychology entry NCI Thesaurus ID  \\\n",
       "14314                                NaN              NaN   \n",
       "30007                                NaN              NaN   \n",
       "8437                                 NaN              NaN   \n",
       "49721                                NaN              NaN   \n",
       "64447                                NaN              NaN   \n",
       "\n",
       "      J. Paul Getty Museum agent ID  \n",
       "14314                           NaN  \n",
       "30007                           NaN  \n",
       "8437                            NaN  \n",
       "49721                           NaN  \n",
       "64447                           NaN  \n",
       "\n",
       "[5 rows x 1050 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('columns.txt', 'w') as f:\n",
    "    for column in df.columns:\n",
    "        f.write(column + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write df to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'processed_schools_{time.time()}.csv'\n",
    "\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f'Wrote df to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'instance of' column to turn lists into separate rows\n",
    "df_exploded = df.explode('instance of')\n",
    "\n",
    "# Count the occurrences of each value in 'instance of'\n",
    "instance_counts = df_exploded['instance of'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(instance_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_instance_counts = pd.DataFrame(instance_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('instance_counts.txt', 'w') as file:\n",
    "    for value, count in instance_counts.items():\n",
    "        file.write(f\"{value}: {count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows with certain values for instanceof\n",
    "instances_to_remove = ['faculty', 'organization', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put items back into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_exploded.groupby('wd_id')['instance of'].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['merged_column'] = df.apply(\n",
    "    lambda row: row['located in the administrative territorial entity'] + row['located in the present-day administrative territorial entity'] + row['location'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['name', 'wd_id', 'country', 'instance of', 'parent organization', 'owner of', 'logo image', 'official website', 'Instagram username', 'X username', 'street address', 'admission rate', 'count of students', 'postal code', 'inception', 'has part(s)', 'image', 'Facebook username', 'has subsidiary', 'official name', 'headquarters location', 'LinkedIn company or organization ID', 'short name', 'location', 'YouTube channel ID', 'coat of arms image', 'seal image', 'owned by', 'board member', 'tuition fee', 'subclass of', 'IRS Employer Identification Number', 'nickname', 'operating area', 'small logo or icon']\n",
    "\n",
    "subset_df = df[cols_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>wd_id</th>\n",
       "      <th>country</th>\n",
       "      <th>instance of</th>\n",
       "      <th>parent organization</th>\n",
       "      <th>owner of</th>\n",
       "      <th>logo image</th>\n",
       "      <th>official website</th>\n",
       "      <th>Instagram username</th>\n",
       "      <th>X username</th>\n",
       "      <th>...</th>\n",
       "      <th>coat of arms image</th>\n",
       "      <th>seal image</th>\n",
       "      <th>owned by</th>\n",
       "      <th>board member</th>\n",
       "      <th>tuition fee</th>\n",
       "      <th>subclass of</th>\n",
       "      <th>IRS Employer Identification Number</th>\n",
       "      <th>nickname</th>\n",
       "      <th>operating area</th>\n",
       "      <th>small logo or icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22437</th>\n",
       "      <td>Midwood High School</td>\n",
       "      <td>Q10749664</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[high school]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[http://www.midwoodhighschool.org/]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name      wd_id                     country  \\\n",
       "22437  Midwood High School  Q10749664  [United States of America]   \n",
       "\n",
       "         instance of parent organization owner of logo image  \\\n",
       "22437  [high school]                 NaN      NaN        NaN   \n",
       "\n",
       "                          official website Instagram username X username  ...  \\\n",
       "22437  [http://www.midwoodhighschool.org/]                NaN        NaN  ...   \n",
       "\n",
       "      coat of arms image seal image owned by board member tuition fee  \\\n",
       "22437                NaN        NaN      NaN          NaN         NaN   \n",
       "\n",
       "      subclass of IRS Employer Identification Number nickname operating area  \\\n",
       "22437         NaN                                NaN      NaN            NaN   \n",
       "\n",
       "      small logo or icon  \n",
       "22437                NaN  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58237, 35)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 columns without any content\n"
     ]
    }
   ],
   "source": [
    "# drop all columns where one or zero rows have value\n",
    "\n",
    "initial_count = subset_df.shape[1]\n",
    "\n",
    "subset_df = subset_df.dropna(axis=1, how='all')\n",
    "subset_df = subset_df.loc[:, subset_df.notna().sum() > 1]\n",
    "subset_df = subset_df[['name'] + ['wd_id'] + ['nickname'] + [col for col in subset_df.columns if col != 'name' and col != 'wd_id' and col != 'nickname']]\n",
    "\n",
    "final_count = subset_df.shape[1]\n",
    "dropped_count = initial_count - final_count\n",
    "print(f\"Dropping {dropped_count} columns without any content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote df to processed_schools_min_cols_1732548646.9518888.csv\n"
     ]
    }
   ],
   "source": [
    "file_name = f'processed_schools_min_cols_{time.time()}.csv'\n",
    "\n",
    "subset_df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f'Wrote df to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-list items\n",
    "import numpy as np\n",
    "\n",
    "for col in subset_df.columns:\n",
    "    subset_df[col] = subset_df[col].apply(\n",
    "        lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_df.head())\n",
    "print(subset_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>wd_id</th>\n",
       "      <th>nickname</th>\n",
       "      <th>country</th>\n",
       "      <th>instance of</th>\n",
       "      <th>parent organization</th>\n",
       "      <th>owner of</th>\n",
       "      <th>logo image</th>\n",
       "      <th>official website</th>\n",
       "      <th>Instagram username</th>\n",
       "      <th>...</th>\n",
       "      <th>YouTube channel ID</th>\n",
       "      <th>coat of arms image</th>\n",
       "      <th>seal image</th>\n",
       "      <th>owned by</th>\n",
       "      <th>board member</th>\n",
       "      <th>tuition fee</th>\n",
       "      <th>subclass of</th>\n",
       "      <th>IRS Employer Identification Number</th>\n",
       "      <th>operating area</th>\n",
       "      <th>small logo or icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>Phillips Academy</td>\n",
       "      <td>Q1432645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[United States of America, United States of Am...</td>\n",
       "      <td>[high school, high school, high school, high s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://www.andover.edu/, https://www.andover...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53333</th>\n",
       "      <td>Beacon City Schools</td>\n",
       "      <td>Q4875911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[school district]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[http://www.beaconcityk12.org/]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26931</th>\n",
       "      <td>Academy of Saint Joseph</td>\n",
       "      <td>Q4671524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[university-preparatory school]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[http://www.asjli.org]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33560</th>\n",
       "      <td>Tennessee Virtual Academy</td>\n",
       "      <td>Q48977549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[school]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38555</th>\n",
       "      <td>Valencia College Lake Nona Campus</td>\n",
       "      <td>Q35190385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[academic library]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name      wd_id nickname  \\\n",
       "12088                   Phillips Academy   Q1432645      NaN   \n",
       "53333                Beacon City Schools   Q4875911      NaN   \n",
       "26931            Academy of Saint Joseph   Q4671524      NaN   \n",
       "33560          Tennessee Virtual Academy  Q48977549      NaN   \n",
       "38555  Valencia College Lake Nona Campus  Q35190385      NaN   \n",
       "\n",
       "                                                 country  \\\n",
       "12088  [United States of America, United States of Am...   \n",
       "53333                         [United States of America]   \n",
       "26931                         [United States of America]   \n",
       "33560                                                NaN   \n",
       "38555                         [United States of America]   \n",
       "\n",
       "                                             instance of parent organization  \\\n",
       "12088  [high school, high school, high school, high s...                 NaN   \n",
       "53333                                  [school district]                 NaN   \n",
       "26931                    [university-preparatory school]                 NaN   \n",
       "33560                                           [school]                 NaN   \n",
       "38555                                 [academic library]                 NaN   \n",
       "\n",
       "      owner of logo image                                   official website  \\\n",
       "12088      NaN        NaN  [https://www.andover.edu/, https://www.andover...   \n",
       "53333      NaN        NaN                    [http://www.beaconcityk12.org/]   \n",
       "26931      NaN        NaN                             [http://www.asjli.org]   \n",
       "33560      NaN        NaN                                                NaN   \n",
       "38555      NaN        NaN                                                NaN   \n",
       "\n",
       "      Instagram username  ... YouTube channel ID coat of arms image  \\\n",
       "12088                NaN  ...                NaN                NaN   \n",
       "53333                NaN  ...                NaN                NaN   \n",
       "26931                NaN  ...                NaN                NaN   \n",
       "33560                NaN  ...                NaN                NaN   \n",
       "38555                NaN  ...                NaN                NaN   \n",
       "\n",
       "      seal image owned by board member tuition fee subclass of  \\\n",
       "12088        NaN      NaN          NaN         NaN         NaN   \n",
       "53333        NaN      NaN          NaN         NaN         NaN   \n",
       "26931        NaN      NaN          NaN         NaN         NaN   \n",
       "33560        NaN      NaN          NaN         NaN         NaN   \n",
       "38555        NaN      NaN          NaN         NaN         NaN   \n",
       "\n",
       "      IRS Employer Identification Number operating area small logo or icon  \n",
       "12088                                NaN            NaN                NaN  \n",
       "53333                                NaN            NaN                NaN  \n",
       "26931                                NaN            NaN                NaN  \n",
       "33560                                NaN            NaN                NaN  \n",
       "38555                                NaN            NaN                NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nickname\n",
       "[APU]                                                                                                                                                                                                                            1\n",
       "[Brick City, Brick City, Brick City, Brick City, Brick City, Brick City, Brick City, Brick City, Brick City]                                                                                                                     1\n",
       "[APUS, APUS]                                                                                                                                                                                                                     1\n",
       "[Seminex, Seminex]                                                                                                                                                                                                               1\n",
       "[Garden of Enid, Garden of Enid, Garden of Enid, Garden of Enid]                                                                                                                                                                 1\n",
       "[VI4]                                                                                                                                                                                                                            1\n",
       "[IIAD]                                                                                                                                                                                                                           1\n",
       "[Colegio Adoratrices]                                                                                                                                                                                                            1\n",
       "[The Brook]                                                                                                                                                                                                                      1\n",
       "[AMU]                                                                                                                                                                                                                            1\n",
       "[Timberwolves]                                                                                                                                                                                                                   1\n",
       "[Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State, Minnesota State]    1\n",
       "[Chico State, Chico State, Chico State, Chico State, Chico State, Chico State]                                                                                                                                                   1\n",
       "[CUNY, CUNY, CUNY, CUNY, CUNY]                                                                                                                                                                                                   1\n",
       "[U of M, U of M]                                                                                                                                                                                                                 1\n",
       "[Cornell CIS, Cornell CIS, Cornell CIS, Cornell CIS, Cornell CIS, Cornell Bowers CIS, Cornell Bowers CIS, Cornell Bowers CIS, Cornell Bowers CIS, Cornell Bowers CIS]                                                            1\n",
       "[Ole Miss, Ole Miss]                                                                                                                                                                                                             1\n",
       "[AI2, AI2]                                                                                                                                                                                                                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df['nickname'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset_df.col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge in nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'processed_schools_min_cols_1732026738.218009.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "import random\n",
    "\n",
    "def fetch_nicknames(wikidata_id):\n",
    "    query = f\"\"\"\n",
    "    SELECT ?itemLabel ?altLabel WHERE {{\n",
    "        BIND(wd:{wikidata_id} AS ?item)  # Bind the input entity to ?item\n",
    "        OPTIONAL {{ ?item skos:altLabel ?altLabel . FILTER (LANG(?altLabel) = \"en\") }}\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    \n",
    "    # Execute the query and fetch results\n",
    "    sparql.query()\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Extract nicknames (altLabels) from results\n",
    "    nicknames = [result.get('altLabel')['value'] for result in results['results']['bindings'] if result.get('altLabel')]\n",
    "    return nicknames\n",
    "\n",
    "def fetch_entity_with_retry(entity, max_retries=5, backoff_factor=1.5):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Replace this with the actual API call\n",
    "            result = fetch_nicknames(entity)  # Your function that fetches the entity\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # If a 429 error occurs, handle it\n",
    "            if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 429:\n",
    "                retries += 1\n",
    "                wait_time = backoff_factor ** retries + random.uniform(0, 2)\n",
    "                print(f\"Rate limit hit. Retrying in {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                retries += 1\n",
    "                wait_time = backoff_factor ** retries + random.uniform(0, 2)\n",
    "                print(f\"Error getting {entity}, {e}\")\n",
    "                time.sleep(wait_time)\n",
    "    print(\"Max retries reached. Skipping this entity.\")\n",
    "    return None  # Return None if retries are exhausted\n",
    "\n",
    "def merge_nicknames_with_csv(csv_file, wikidata_column):\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Create an empty list to store the nicknames\n",
    "    nicknames_list = []\n",
    "\n",
    "    # Iterate through each row and fetch the nicknames for the Wikidata ID\n",
    "    for _index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Fetching Nicknames\", unit=\"row\"):\n",
    "        wikidata_id = row[wikidata_column]\n",
    "        nicknames = fetch_entity_with_retry(wikidata_id)\n",
    "        nicknames_list.append(nicknames)\n",
    "\n",
    "    # Add the nicknames as a new column to the DataFrame\n",
    "    df['nicknames'] = nicknames_list\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV\n",
    "    with tqdm(total=len(df), desc=\"Saving CSV\", unit=\"row\") as pbar:\n",
    "        df.to_csv('updated_with_nicknames.csv', index=False)\n",
    "        pbar.update(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = file_name  # Replace with your existing CSV file path\n",
    "wikidata_column = 'wd_id'  # Replace with the column containing Wikidata IDs (e.g., Q536709)\n",
    "\n",
    "merge_nicknames_with_csv(csv_file, wikidata_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'processed_schools_min_cols_{time.time()}.csv'\n",
    "\n",
    "subset_df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f'Wrote df to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('schools.csv', 'r') as file:\n",
    "    df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
